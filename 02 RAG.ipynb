{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a85c8c5c-6b54-40c4-9f37-9bcc84f7895d",
   "metadata": {},
   "source": [
    "## Overview Structure\n",
    "1. Files Watchdog ( async trigger->2 )\n",
    "2. Text & Info extraction (tika) ->\n",
    "3. Do embedding & storage (gpt-API + chroma) ->\n",
    "4. Function : Vector Search (gpt-API, Bart)\n",
    "5. Function : Summarization  (gpt-API, Bart)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44ae65ae-1228-4903-b1c4-c8f81d8dac73",
   "metadata": {},
   "source": [
    "### 3. Chroma : Vector Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "228b8718-6ecd-4aad-b792-338cc2dc26eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:13: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\transformers\\tokenization_utils_base.py:1602: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# !pip install -U chromadb==0.5.0  # 0.5.4 windows crash \n",
    "import chromadb\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer # from sentence transformer\n",
    "from chromadb.utils.embedding_functions import SentenceTransformerEmbeddingFunction # from chromdb utils\n",
    "import os\n",
    "from src import search_chroma, query_openai, io_local\n",
    "\n",
    "if 0:\n",
    "    em_model = SentenceTransformer('paraphrase-albert-small-v2')\n",
    "    def emb_fn(texts):\n",
    "        return em_model.encode(texts, convert_to_tensor=True).tolist()\n",
    "else:\n",
    "    emb_fn = SentenceTransformerEmbeddingFunction(model_name='paraphrase-multilingual-MiniLM-L12-v2') # HuggingFace, for Chinese\n",
    "\n",
    "client = chromadb.PersistentClient(path=\"../../Data/chromabase\")\n",
    "# client.delete_collection(name=\"project-files\")\n",
    "collection = client.get_or_create_collection(\"project-files\", embedding_function=emb_fn) # collection is in memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "073fc00f-0be9-4cbc-81c7-f0ed23787358",
   "metadata": {},
   "outputs": [],
   "source": [
    "a=collection.get(include=['metadatas'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d414a993-7a3a-4c76-81bd-de5e7cf21009",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "b=pd.DataFrame(a['metadatas'])\n",
    "b['ids'] = a['ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d6577c34-2c41-44ab-bfca-e82fa3faa2db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>type</th>\n",
       "      <th>size</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>E:\\数智项目资料\\NQI\\样本资产管理平台\\一期 - 人工智能样本资源管理及可视化.docx</td>\n",
       "      <td>docx</td>\n",
       "      <td>50983</td>\n",
       "      <td>1.727059e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>E:\\数智项目资料\\NQI\\样本资产管理平台\\二期 - 人工智能样本资源管理及可视化二期.docx</td>\n",
       "      <td>docx</td>\n",
       "      <td>524815</td>\n",
       "      <td>1.727059e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                path  type    size  \\\n",
       "0    E:\\数智项目资料\\NQI\\样本资产管理平台\\一期 - 人工智能样本资源管理及可视化.docx  docx   50983   \n",
       "1  E:\\数智项目资料\\NQI\\样本资产管理平台\\二期 - 人工智能样本资源管理及可视化二期.docx  docx  524815   \n",
       "\n",
       "           date  \n",
       "0  1.727059e+09  \n",
       "1  1.727059e+09  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(io_local.list_dir_metas(\"E:\\\\数智项目资料\\\\NQI\\\\样本资产管理平台\\\\\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad634a5d-977c-43ec-a37a-c6fa29c7b306",
   "metadata": {},
   "source": [
    "#### 3.1 Synchronize & Update local files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43d1f484-b119-4c08-8173-6ffec733400b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All: 32  Update: 0  Delete: 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'ids': [['E:\\\\数智项目资料\\\\NQI\\\\资料搜集\\\\2023申国内外现状(抽取).pdf',\n",
       "   'E:\\\\数智项目资料\\\\NQI\\\\资料搜集\\\\2023年火灾防控-申报书.pdf',\n",
       "   'E:\\\\数智项目资料\\\\NQI\\\\综述\\\\综述文献\\\\新型电力系统中人工智能应用的关键技术-蒲天骄.pdf']],\n",
       " 'distances': [[17.384515741805547, 18.840491924595145, 19.725080687160215]],\n",
       " 'metadatas': None,\n",
       " 'embeddings': None,\n",
       " 'documents': None,\n",
       " 'uris': None,\n",
       " 'data': None}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_metas_update, db_delete = search_chroma.sync_dir(collection, 'E:\\\\数智项目资料\\\\NQI')\n",
    "print('All:', collection.count(), ' Update:', len(f_metas_update), ' Delete:', len(db_delete))\n",
    "\n",
    "collection.query(\n",
    "    query_texts=\"如何防止电力系统火灾的发生？\", include = ['distances'], n_results = 3\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a1d3726-0144-48a4-aebe-d1e964239a3d",
   "metadata": {},
   "source": [
    "### 4. Answer question by context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3a69f4d-63c6-40eb-88ce-0fe65971a710",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "searched files id:  [['E:\\\\数智项目资料\\\\NQI\\\\深圳局\\\\NQI-5.1.docx', 'E:\\\\数智项目资料\\\\NQI\\\\深圳局\\\\NQI-5.1_v1.docx', 'E:\\\\数智项目资料\\\\NQI\\\\综述\\\\综述文献\\\\数据与知识联合驱动的人工智能方法在电力调度中的应用综述-李鹏.pdf']]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'人工智能与电力行业结合的难点主要包括以下几个方面：\\n\\n1. **数据集构建与管理**：需要针对电力行业的复杂场景（如“源网荷储”）制定标准化的数据集，确保数据的类别、精度和数量满足行业要求，并保证数据的安全性和合规性。\\n\\n2. **模型验证与认证**：人工智能模型必须经过严格的检验和认证，确保其在实际应用中的准确性、适用性和稳定性，这对于电力行业来说尤其重要，因为它关系到系统的安全与稳定。\\n\\n3. **多模型协同与升级**：电力系统中存在多种人工智能模型，需要建立统一的模型管理体系，支持云边端模型的协同与远程升级，以适应系统的实时需求。\\n\\n4. **安全性与实时性**：电力行业对数据处理和模型运用的安全性和实时性要求极高，任何延迟或不准确都可能导致灾难性后果。\\n\\n5. **标准化体系的缺失**：目前针对电力行业的人工智能应用标准和测量指标仍然不足，缺乏具体的行业特性和定量评估标准，使得实际应用中的验证和评估变得困难。\\n\\n根据文档中的信息，以上这些难点体现了人工智能在电力行业实际应用中的复杂性与挑战性。'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q = \"人工智能与电力行业结合有哪些难点?\"\n",
    "\n",
    "search_results = collection.query(\n",
    "    query_texts=Q, include = ['distances','documents'], n_results = 3\n",
    ")\n",
    "print('searched files id: ', search_results['ids']) #  metadatas / distances / documents  \n",
    "response = query_openai.get_response_openai(Q, ''.join(search_results['documents'][0]), 'gpt-4o-mini', task='refer')\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "28332087-5019-443e-bbc5-33b203a52eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Q1: by Q_Text (Embedding Indexing)\n",
    "Q = dataset['question'][:1]\n",
    "results = collection.query(query_texts=Q, n_results=2, include = ['documents', 'metadatas'])\n",
    "\n",
    "### Q2: by Q_Text + (Embedding Indexing)\n",
    "# Q = dataset['question'][:5]\n",
    "# results = collection.query(query_texts=Q, n_results=2, include = ['metadatas', 'documents'],\n",
    "#                            where_document = {\"$contains\": \"Chemistry\"})\n",
    "\n",
    "### Q3: by Hard filter\n",
    "# results = collection.get(ids = [\"11\"], include = ['embeddings', 'documents'])\n",
    "# results = collection.get(where = {'source':'notion'} )\n",
    "results = collection.query(query_texts=Q[0], n_results=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d58a3f3-ac85-4bce-901b-71ba9df4bc00",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "MAIN_CFG = {\n",
    "    'model':\"gpt-4o-mini\", # can be 'gpt-4o', 'o1-mini'        \n",
    "    'messages':[\n",
    "        {\"role\": \"user\", \"content\": \"explain in 300 words what's fine-tune in llm?\"}\n",
    "    ],\n",
    "    'max_tokens':400,\n",
    "    'temperature':1\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b21cb521-56c0-4dc8-9a00-1902e3d31748",
   "metadata": {},
   "source": [
    "### Test & Debug"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "067a75f4-36b2-4f4b-acb1-a4242dd5f6b2",
   "metadata": {},
   "source": [
    "#### Test 'search + query' via test-doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b4fc913-1ece-4dfb-8600-82791c3ae6d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src import search_chroma, query_openai\n",
    "\n",
    "q = \"are there anything about sport?\"\n",
    "search_results = collection.query(query_texts=Q, n_results=2, include = ['documents', 'metadatas'])\n",
    "print('searched files id: ', search_results['ids'][0]) #  metadatas / distances / documents  \n",
    "response = query_openai.get_response_openai(q, ''.join(search_results['documents'][0]), 'gpt-4o-mini')\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29fea459-08d3-4809-9f36-5d6edf5e0cad",
   "metadata": {},
   "source": [
    "#### Test From HuggingFace dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "607dd76d-181f-4eb3-b3c7-e8cc80c77bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## large dataset : SciQ dataset from HuggingFace\n",
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"sciq\", split=\"train\")\n",
    "dataset = dataset.filter(lambda x: x[\"support\"] != \"\")\n",
    "dataset = dataset.select(range(1000))\n",
    "\n",
    "print(\"Number of questions with support: \", len(dataset))\n",
    "\n",
    "## Load the supporting evidence in batches of 1000\n",
    "col2 = client.get_or_create_collection(\"sciq_supports\")\n",
    "batch_size = 20\n",
    "for i in tqdm(range(0, len(dataset), batch_size)):\n",
    "    collection.add(\n",
    "        ids=[ str(i) for i in range(i, min(i + batch_size, len(dataset))) ],  # IDs are just strings\n",
    "        documents=dataset[\"support\"][i : i + batch_size],\n",
    "        metadatas=[\n",
    "            {\"type\": \"support\"} for _ in range(i, min(i + batch_size, len(dataset)))\n",
    "        ],\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e0c86b3-a5a4-4184-adf8-8c138bda9530",
   "metadata": {},
   "source": [
    "#### Problem: Chinese embedding\n",
    "- sentence embedding: 'paraphrase-multilingual-MiniLM-L12-v2'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06e1311a-7f82-4961-b106-6fa742e31d9d",
   "metadata": {},
   "source": [
    "#### Problem: Tokens too large after semantic search\n",
    "- Truncate + Concatenate: File=chunks / Sums[]=summerize(chunks[]) / RC=summerize(Sums[])\n",
    "- Build section/keyword-metadata + Filter by metadata\n",
    "    - chunk = [\"'section:'...chunk\"], meta = {keywords}\n",
    "    - semantic_search(chunks) + keywords_filter(keywords)\n",
    "- Todo: Put file-name to metadata, multiple-trunks = 1-fname\n",
    "    - ids = 'path' + str(chunk-id)\n",
    "    - update: delete db_meata['path'] == file['path'] / insert\n",
    "    - delete: delete db_meata['path'] == file['path']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6748438f-e828-4112-98f1-e0161a69e668",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
